{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan 25 02:23:21 2017\n",
    "\n",
    "@author: jkim\n",
    "\"\"\"\n",
    "\n",
    "## Shapelets for time series classification \n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import measure\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pylab import rcParams\n",
    "mpl.rcParams['figure.figsize'] = (6, 6) \n",
    "\n",
    "## Step 1: Converting an object contour to a 1D signal \n",
    "def draw_leaf(image):\n",
    "    img = mpimg.imread(image)\n",
    "    cy, cx = ndi.center_of_mass(img)\n",
    "    return img, (cx, cy)\n",
    "    \n",
    "def get_contour(img, thresh=.8):\n",
    "    contours = measure.find_contours(img, thresh)\n",
    "    return max(contours, key=len)  # Take longest one\n",
    "    \n",
    "def convert_to_1d(file, sample=250, thresh=.8, plot=False, norm=True):\n",
    "    img, (cx, cy) = draw_leaf(file)\n",
    "    contour = get_contour(img, thresh)\n",
    "    distances = [manhattan_distance([cx, cy], [contour[i][0], contour[i][1]]) for i in range(0, len(contour), sample)]\n",
    "    distances.extend(distances)\n",
    "    if plot:\n",
    "        f, axarr = plt.subplots(2, sharex=False) \n",
    "        axarr[0].imshow(img, cmap='Set3')\n",
    "        axarr[0].plot(contour[::,1], contour[::,0], linewidth=0.5)\n",
    "        axarr[0].scatter(cx, cy)\n",
    "        axarr[1].plot(distances)\n",
    "        plt.show()\n",
    "    if norm: \n",
    "        return np.divide(distances, max(distances))\n",
    "    else:\n",
    "        return distances  # Extend it twice so that it is cyclic\n",
    "\n",
    "def manhattan_distance(a, b, min_dist=float('inf')):\n",
    "    dist = 0\n",
    "    for x, y in zip(a, b):\n",
    "        dist += np.abs(float(x)-float(y))\n",
    "        if dist >= min_dist: return None\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-402d88f59015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#SIM[0] = similar(data[1], data[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1584\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mSIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#similar(distances1, distances1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(1, 1584):\n",
    " #  distance[i] = convert_to_1d('/Users/jkim/Documents/leaf_image/images/i.jpg', plot=True, norm=1)\n",
    "    data.append(convert_to_1d('/Users/jimmytran/Workspace/leaf-classification/images/'+str(i)+'.jpg', plot = False, norm=1))\n",
    "#distances1 = convert_to_1d('/Users/jkim/Documents/leaf_image/images/1.jpg', plot=True, norm=1)\n",
    "#distances2 = convert_to_1d('/Users/jkim/Documents/leaf_image/images/2.jpg', plot=True, norm=1)\n",
    "#distances3 = convert_to_1d('/Users/jkim/Documents/leaf_image/images/3.jpg', plot=True, norm=1)\n",
    "#distances4 = convert_to_1d('/Users/jkim/Documents/leaf_image/images/4.jpg', plot=True, norm=1)\n",
    "#distances5 = convert_to_1d('/Users/jkim/Documents/leaf_image/images/5.jpg', plot=True, norm=1)\n",
    "\n",
    "#data.append((convert_to_1d('/Users/jkim/Documents/leaf_image/images/'+str(number)+'.jpg', plot=0), leaf_map[name]))\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "SIM = []\n",
    "#SIM[0] = similar(data[1], data[1])\n",
    "for i in range(1, 1584):\n",
    "    SIM.append(similar(data[1], data[i]))\n",
    "\n",
    "#similar(distances1, distances1)\n",
    "#similar(distances1, distances2)\n",
    "#similar(distances1, distances3)\n",
    "#similar(distances1, distances4)\n",
    "#similar(distances1, distances5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "(990, 194)\n",
      "RangeIndex(start=0, stop=990, step=1)\n",
      "Index([u'id', u'species', u'margin1', u'margin2', u'margin3', u'margin4',\n",
      "       u'margin5', u'margin6', u'margin7', u'margin8',\n",
      "       ...\n",
      "       u'texture55', u'texture56', u'texture57', u'texture58', u'texture59',\n",
      "       u'texture60', u'texture61', u'texture62', u'texture63', u'texture64'],\n",
      "      dtype='object', length=194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:14: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "##########################  csv file loading. #########################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/jimmytran/Workspace/leaf-classification/train.csv\") #, nrows=1)\n",
    "test_data = pd.read_csv(\"/Users/jimmytran/Workspace/leaf-classification/test.csv\") #, nrows=1)\n",
    "\n",
    "#np.savetxt('train_data.csv', ())\n",
    "#import csv\n",
    "#myfile_TRAIN_DATA = open(\"/Users/jkim/Documents/leaf_image/TRAIN\", 'wb') #, nrows=1)\n",
    "#TRAIN_DATA = csv.writer(myfile_TRAIN_DATA, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "DATA = pd.concat([train_data, test_data])\n",
    "DATA = DATA.sort(['id'], ascending=[True])\n",
    "\n",
    "\n",
    "#DATA = pd.merge(train_data, test_data, on=['id'])\n",
    "\n",
    "\n",
    "print len(train_data)\n",
    "print train_data.shape\n",
    "print train_data.index\n",
    "print train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "(594, 193)\n",
      "RangeIndex(start=0, stop=594, step=1)\n",
      "Index([u'id', u'margin1', u'margin2', u'margin3', u'margin4', u'margin5',\n",
      "       u'margin6', u'margin7', u'margin8', u'margin9',\n",
      "       ...\n",
      "       u'texture55', u'texture56', u'texture57', u'texture58', u'texture59',\n",
      "       u'texture60', u'texture61', u'texture62', u'texture63', u'texture64'],\n",
      "      dtype='object', length=193)\n"
     ]
    }
   ],
   "source": [
    "print len(test_data)\n",
    "print test_data.shape\n",
    "print test_data.index\n",
    "print test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#for val in range(1,len(SIM)):\n",
    "#    train_data.ix[val] = SIM[val]\n",
    "\n",
    "#for val in range(1, len(SIM)):\n",
    "#    DATA.ix[val] = SIM[val]\n",
    "\n",
    "#SIM = pd.DataFrame(SIM)\n",
    "\n",
    "F_DATA = DATA\n",
    "F_DATA = F_DATA.sort(['id'], ascending=[True])\n",
    "\n",
    "# F_DATA =DATA.join(SIM)\n",
    "#remain = [p for p in F_DATA.id if p in train_data.id]\n",
    "\n",
    "#train = []\n",
    "#for p in remain:\n",
    "#    train.append(F_DATA[p])\n",
    "#train = pd.DataFrame(train)\n",
    "\n",
    "train = F_DATA[F_DATA.id.isin(train_data.id)]\n",
    "test = F_DATA[F_DATA.id.isin(test_data.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       Acer_Opalus\n",
      "1             Pterocarya_Stenoptera\n",
      "2              Quercus_Hartwissiana\n",
      "3                   Tilia_Tomentosa\n",
      "4                Quercus_Variabilis\n",
      "5              Magnolia_Salicifolia\n",
      "6               Quercus_Canariensis\n",
      "7                     Quercus_Rubra\n",
      "8                   Quercus_Brantii\n",
      "9                    Salix_Fragilis\n",
      "10                  Zelkova_Serrata\n",
      "11            Betula_Austrosinensis\n",
      "12                  Quercus_Pontica\n",
      "13                   Quercus_Afares\n",
      "14                Quercus_Coccifera\n",
      "15                  Fagus_Sylvatica\n",
      "16                      Phildelphus\n",
      "17                    Acer_Palmatum\n",
      "18                Quercus_Pubescens\n",
      "19                Populus_Adenopoda\n",
      "20                  Quercus_Trojana\n",
      "21               Quercus_Variabilis\n",
      "22                Alnus_Sieboldiana\n",
      "23                     Quercus_Ilex\n",
      "24              Arundinaria_Simonii\n",
      "25                  Acer_Platanoids\n",
      "26           Quercus_Phillyraeoides\n",
      "27                 Cornus_Chinensis\n",
      "28           Quercus_Phillyraeoides\n",
      "29                  Fagus_Sylvatica\n",
      "                   ...             \n",
      "960               Quercus_Vulcanica\n",
      "961                  Salix_Fragilis\n",
      "962                 Tilia_Tomentosa\n",
      "963           Populus_Grandidentata\n",
      "964               Prunus_X_Shmittii\n",
      "965             Quercus_x_Hispanica\n",
      "966                   Quercus_Suber\n",
      "967                   Alnus_Viridis\n",
      "968                   Acer_Palmatum\n",
      "969             Quercus_Rhysophylla\n",
      "970                  Quercus_Cerris\n",
      "971                  Quercus_Texana\n",
      "972                       Acer_Mono\n",
      "973               Quercus_Vulcanica\n",
      "974                   Quercus_Nigra\n",
      "975     Rhododendron_x_Russellianum\n",
      "976                 Acer_Capillipes\n",
      "977               Quercus_Pubescens\n",
      "978                   Alnus_Viridis\n",
      "979             Quercus_x_Hispanica\n",
      "980                   Quercus_Suber\n",
      "981    Viburnum_x_Rhytidophylloides\n",
      "982                   Quercus_Nigra\n",
      "983                 Quercus_Phellos\n",
      "984                    Ilex_Cornuta\n",
      "985            Magnolia_Salicifolia\n",
      "986                     Acer_Pictum\n",
      "987              Alnus_Maximowiczii\n",
      "988                   Quercus_Rubra\n",
      "989                  Quercus_Afares\n",
      "Name: species, dtype: object\n",
      "0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "5      NaN\n",
      "6      NaN\n",
      "7      NaN\n",
      "8      NaN\n",
      "9      NaN\n",
      "10     NaN\n",
      "11     NaN\n",
      "12     NaN\n",
      "13     NaN\n",
      "14     NaN\n",
      "15     NaN\n",
      "16     NaN\n",
      "17     NaN\n",
      "18     NaN\n",
      "19     NaN\n",
      "20     NaN\n",
      "21     NaN\n",
      "22     NaN\n",
      "23     NaN\n",
      "24     NaN\n",
      "25     NaN\n",
      "26     NaN\n",
      "27     NaN\n",
      "28     NaN\n",
      "29     NaN\n",
      "      ... \n",
      "564    NaN\n",
      "565    NaN\n",
      "566    NaN\n",
      "567    NaN\n",
      "568    NaN\n",
      "569    NaN\n",
      "570    NaN\n",
      "571    NaN\n",
      "572    NaN\n",
      "573    NaN\n",
      "574    NaN\n",
      "575    NaN\n",
      "576    NaN\n",
      "577    NaN\n",
      "578    NaN\n",
      "579    NaN\n",
      "580    NaN\n",
      "581    NaN\n",
      "582    NaN\n",
      "583    NaN\n",
      "584    NaN\n",
      "585    NaN\n",
      "586    NaN\n",
      "587    NaN\n",
      "588    NaN\n",
      "589    NaN\n",
      "590    NaN\n",
      "591    NaN\n",
      "592    NaN\n",
      "593    NaN\n",
      "Name: species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print train['species']\n",
    "print test['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_train_orig = train.species\n",
    "y_train_orig = train['species']\n",
    "\n",
    "my_cols = set(train.columns)\n",
    "my_cols.remove('species')\n",
    "my_cols = list(my_cols)\n",
    "\n",
    "X_train_orig = train[my_cols]\n",
    "\n",
    "\n",
    "y_test_orig = test['species']\n",
    "y_train_orig = train['species']\n",
    "\n",
    "len(np.unique(list(y_train_orig)))\n",
    "\n",
    "my_cols = set(test.columns)\n",
    "my_cols.remove('species')\n",
    "my_cols = list(my_cols)\n",
    "\n",
    "X_test_orig = test[my_cols]\n",
    "\n",
    "test_col = X_test_orig.columns\n",
    "train_col = X_train_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'shape10', u'texture39', u'shape17', u'shape16', u'shape35',\n",
      "       u'shape34', u'shape37', u'shape36', u'shape31', u'margin22',\n",
      "       ...\n",
      "       u'margin36', u'margin35', u'margin34', u'margin33', u'margin32',\n",
      "       u'margin31', u'margin30', u'shape13', u'margin25', u'shape11'],\n",
      "      dtype='object', length=193)\n"
     ]
    }
   ],
   "source": [
    "X_test_orig.shape\n",
    "print test_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "\n",
    "# Importance rate calculation using RandomForestClassifier. \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "feat_labels = X_train_orig.columns \n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "forest.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(importances)\n",
    "print(indices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for f in range(X_train_orig.shape[1]):\n",
    "#    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "#X_train_orig = forest.transform(X_train_orig, threshold=.05)\n",
    "#X_test_orig = forest.transform(X_test_orig, threshold=.05)\n",
    "#X_train_orig \n",
    "\n",
    "\n",
    "\n",
    "# put into the data frame. for X-test data \n",
    "X_test_orig = pd.DataFrame(sc.fit_transform(X_test_orig))\n",
    "# interpolate the missing values using two values sides. \n",
    "X_train_orig = X_train_orig.interpolate()\n",
    "# put into the data frame for X-train data. \n",
    "X_train_orig = pd.DataFrame(sc.fit_transform(X_train_orig))\n",
    "# test column names\n",
    "X_test_orig.columns = test_col\n",
    "# train column names \n",
    "X_train_orig.columns = train_col\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_orig, y_train_orig, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "## learning curves of KNeighborsClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"KNeighborsClassifier\")\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=KNeighborsClassifier(n_neighbors=3), X=X_train_orig, y=y_train_orig, cv=10, n_jobs=1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "plt.plot(train_sizes, train_mean, color = 'blue', marker='o', markersize=5, label = 'training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha = 0.15, color = 'blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha = 0.15, color= 'green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.7, 0.9])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "Y = knn.predict(X_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "#print(knn.score(X_train, Y))\n",
    "print(knn.score(X_train, y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "#coeff_df.columns = ['Features']\n",
    "#coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "#print(coeff_df)\n",
    "\n",
    "\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn import metrics\n",
    "#y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#print(classification_report(y_true, y_pred))\n",
    "#y_pred = clf.predict(X_test).astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
